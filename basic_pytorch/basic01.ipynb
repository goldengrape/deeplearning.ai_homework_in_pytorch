{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch 基础\n",
    "\n",
    "* pytorch和tensorflow一样也是做机器学习的重要框架, 不像tensorflow做出来的变量先是placeholder, 只把位置holder住, 没有往里feed数据之前很难进行调试. pytorch里面的tensor是有值的, 所以应该比较容易debug. \n",
    "\n",
    "* pytorch的另一个好处是貌似比较容易迁移到GPU的运算上, pytorch据说和numpy差不多, 所以如果慢慢熟悉了pytorch, 在程序里用pytorch替代numpy, 以后追求运算速度时只主要相对简单的步骤就可以用上CUDA了. \n",
    "\n",
    "正因为上述原因, 所以我打算用pytorch把deeplearning.ai的课程作业挑一些重写一遍. \n",
    "\n",
    "首先, 按照[Yoshua Bengio实验室MILA开放面向初学者的PyTorch教程](https://github.com/mila-udem/welcome_tutorials) ([机器之心翻译](https://www.jiqizhixin.com/articles/2017-11-16-8)) 熟悉一遍pytorch的基本命令. 必要时也要参考[pytorch中文文档](https://pytorch-cn.readthedocs.io/zh/latest/)的说明. \n",
    "\n",
    "安装就不详细说了, 还是用[cocalc](https://cocalc.com/app)或者[MS azure notebook](https://notebooks.azure.com)的在线版吧, 其中cocalc从善如流已经装好了pytorch, azure notebook里面没有, 但可以参考[这个帖子](https://github.com/Microsoft/AzureNotebooks/issues/201#issuecomment-338466615)的解决方案, 加入一段自动运行的设置, 每次启动之前会安装一遍pytorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T13:33:01.690614Z",
     "start_time": "2017-11-18T13:33:01.686205Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化张量\n",
    "参考https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch/#creation-ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T14:39:45.815431Z",
     "start_time": "2017-11-18T14:39:45.805854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N(0,1)的正态分布随机数\n",
      " 0.5659 -1.3084 -0.3016\n",
      " 0.1248 -0.1061  2.3174\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "[0,1]的均匀分布随机数\n",
      " 0.6926  0.0877  0.9663\n",
      " 0.8277  0.7705  0.3829\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      " 1\n",
      " 2\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"N(0,1)的正态分布随机数{0}\".format(torch.randn(2,3)))\n",
    "print(\"[0,1]的均匀分布随机数{0}\".format(torch.rand(2,3)))\n",
    "print(torch.zeros(2,3))\n",
    "print(torch.ones(2, 3))\n",
    "print(torch.arange(1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转换张量\n",
    "用torch.Tensor可以将List, np array等转换成tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T14:32:08.548047Z",
     "start_time": "2017-11-18T14:32:08.538170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  2\n",
      " 3  4\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "\n",
      "  1   2   3   4\n",
      "  5   6   7   8\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      "  2\n",
      "  6\n",
      " 10\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a=[[1,2],[3,4]]\n",
    "x= torch.Tensor(a)\n",
    "b=np.linspace(1,12,12).reshape(3,4)\n",
    "y=torch.Tensor(b)\n",
    "print(x)\n",
    "print(y)\n",
    "print(y[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取维度\n",
    "用.size()获得tensor的维数, 相当于.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T14:32:14.967328Z",
     "start_time": "2017-11-18T14:32:14.961000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "y=torch.linspace(1,12,12).view(3,4)\n",
    "print(y.size()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshape\n",
    "torch用.view()来做reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T14:32:23.671439Z",
     "start_time": "2017-11-18T14:32:23.662734Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始形态\n",
      "\n",
      "  1   2   3   4\n",
      "  5   6   7   8\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "矮胖\n",
      "\n",
      "  1   2   3   4   5   6\n",
      "  7   8   9  10  11  12\n",
      "[torch.FloatTensor of size 2x6]\n",
      "\n",
      "压扁\n",
      "\n",
      "    1     2     3     4     5     6     7     8     9    10    11    12\n",
      "[torch.FloatTensor of size 1x12]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y=torch.linspace(1,12,12).view(3,4)\n",
    "print(\"原始形态\\n{0}\".format(y))\n",
    "print('矮胖\\n{0}'.format(y.view(-1,6)))\n",
    "print(\"压扁\\n{0}\".format(y.view(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 连接\n",
    "torch.cat,按照不同轴来连接张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T14:44:59.839305Z",
     "start_time": "2017-11-18T14:44:59.830496Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原张量\n",
      " 0  1  2\n",
      " 3  4  5\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "按照0轴方向连接\n",
      " 0  1  2\n",
      " 3  4  5\n",
      " 0  1  2\n",
      " 3  4  5\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n",
      "按照1轴方向连接\n",
      " 0  1  2  0  1  2\n",
      " 3  4  5  3  4  5\n",
      "[torch.FloatTensor of size 2x6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y=torch.arange(0,6).view(2,3)\n",
    "print('原张量{0}'.format(y))\n",
    "print('按照0轴方向连接{0}'.format(torch.cat([y,y],0)))\n",
    "print('按照1轴方向连接{0}'.format(torch.cat([y,y],1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转置\n",
    "* torch.t() 简单的二维转置\n",
    "* torch.transpose()\n",
    "\n",
    "也可以写成y.t()\n",
    "注意是函数, 要有括号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T14:51:15.955549Z",
     "start_time": "2017-11-18T14:51:15.943883Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  1  2\n",
      " 3  4  5\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      " 0  3\n",
      " 1  4\n",
      " 2  5\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n",
      "\n",
      " 0  3\n",
      " 1  4\n",
      " 2  5\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y=torch.arange(0,6).view(2,3)\n",
    "print(y)\n",
    "print(torch.t(y))\n",
    "print(torch.transpose(y,0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切片索引\n",
    "跟常规numpy的相同, 复杂的逻辑切片用torch.masked_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T15:39:04.447497Z",
     "start_time": "2017-11-18T15:39:04.442105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 3\n",
      " 4\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y=torch.arange(0,6)\n",
    "x=(y>=3) & (y<=4)\n",
    "print(y[x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T14:29:21.598103Z",
     "start_time": "2017-11-18T14:29:21.593733Z"
    }
   },
   "source": [
    "# 常用数学运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T15:40:06.377127Z",
     "start_time": "2017-11-18T15:40:06.371701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.4170  0.9972  0.7203\n",
       "[torch.FloatTensor of size 1x3]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "torch.rand(1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 乘法\n",
    "dot乘法, 用一个诡异的torch.mm, 不是torch.dot!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T15:10:20.191578Z",
     "start_time": "2017-11-18T15:10:20.161197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  1  2\n",
      " 3  4  5\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      " 6  5\n",
      " 4  3\n",
      " 2  1\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n",
      "\n",
      "  8   5\n",
      " 44  32\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "\n",
      "  8   5\n",
      " 44  32\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=torch.arange(0,6).view(2,3)\n",
    "y=torch.arange(6,0,-1).view(3,2)\n",
    "print(x)\n",
    "print(y)\n",
    "print(torch.mm(x,y))\n",
    "print(x.mm(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 乘方开方 torch.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T14:32:26.092608Z",
     "start_time": "2017-11-18T14:32:26.084791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  1   2   3   4\n",
       "  5   6   7   8\n",
       "  9  10  11  12\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=torch.linspace(1,12,12).view(3,4)\n",
    "torch.sqrt(y**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 求和, 求积\n",
    "* torch.sum(input,dim)\n",
    "* torch.prod(input,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T15:24:31.482341Z",
     "start_time": "2017-11-18T15:24:31.470364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4   5\n",
      "  6   7   8   9  10\n",
      "[torch.FloatTensor of size 2x5]\n",
      "\n",
      "按0轴求和\n",
      "  7\n",
      "  9\n",
      " 11\n",
      " 13\n",
      " 15\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "按1轴求和\n",
      " 15\n",
      " 40\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "按0轴求乘积\n",
      "  6\n",
      " 14\n",
      " 24\n",
      " 36\n",
      " 50\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "按1轴求乘积\n",
      "   120\n",
      " 30240\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y=torch.linspace(1,10,10).view(2,5)\n",
    "print(y)\n",
    "print(\"按0轴求和{0}\".format(torch.sum(y,0)))\n",
    "print(\"按1轴求和{0}\".format(torch.sum(y,1)))\n",
    "\n",
    "print(\"按0轴求乘积{0}\".format(torch.prod(y,0)))\n",
    "print(\"按1轴求乘积{0}\".format(torch.prod(y,1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 范数\n",
    "torch.norm(input, p, dim, out=None) → Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T15:22:31.145334Z",
     "start_time": "2017-11-18T15:22:31.137468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  1  2\n",
      " 3  4  5\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "1阶范数, 按0轴取\n",
      " 3\n",
      " 5\n",
      " 7\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "2阶范数, 按1轴取\n",
      " 2.2361\n",
      " 7.0711\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y=torch.arange(0,6).view(2,-1)\n",
    "print(y)\n",
    "print(\"1阶范数, 按0轴取{0}\".format(y.norm(p=1,dim=0)))\n",
    "print(\"2阶范数, 按1轴取{0}\".format(y.norm(p=2,dim=1)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "334px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
