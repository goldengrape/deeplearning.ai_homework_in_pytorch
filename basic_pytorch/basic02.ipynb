{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自动微分autograd\n",
    "\n",
    "神经网络中反向传播算法是用微分的链式法则求微分. \n",
    "\n",
    "这一部分貌似pytorch自家的tutorial讲得更清楚些: \n",
    "http://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T09:32:58.249805Z",
     "start_time": "2017-11-19T09:32:58.243654Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable\n",
    "一个变量里包含三个部分\n",
    "![](http://pytorch.org/tutorials/_images/Variable.png)\n",
    "我大概理解是把Tensor放进Variable里面就可以生成. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T07:59:01.442307Z",
     "start_time": "2017-11-19T07:59:01.430463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打印xVariable containing:\n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "x中的data, 好像和直接打印x差别不大,\n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "一个Variable要通过其他过程的生成才有grad_fn, 否则就是个类似常量的东西\n",
      "所以x的grad_fn=None\n",
      "但y=x**2, 所以y的grad_fn=<torch.autograd.function.PowConstantBackward object at 0x117e85138>\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.ones(2, 3), requires_grad=True)\n",
    "print(\"打印x{0}\".format(x))\n",
    "print(\"x中的data, 好像和直接打印x差别不大,{0}\".format(x.data))\n",
    "\n",
    "y=x**2\n",
    "\n",
    "print(\"一个Variable要通过其他过程的生成才有grad_fn, 否则就是个类似常量的东西\")\n",
    "print(\"所以x的grad_fn={0}\".format(x.grad_fn))\n",
    "print(\"但y=x**2, 所以y的grad_fn={0}\".format(y.grad_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 微分\n",
    "如果一个Vairable是通过其他Variable生成的, 就可以进行求导了. 我大学一年级上高数的时候怎么没碰上这种好事. (不过好像当时对Mathematica还比较熟练). \n",
    "\n",
    "只需要先运行y.backward(gradient=xxx), 注意如果不指定的时候y.backward()相当于y.backward(torch.Tensor([1.0])), 但如果y是个矩阵或者向量, 就会报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T10:50:10.231866Z",
     "start_time": "2017-11-19T10:50:10.217600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=Variable containing:\n",
      " 0.5000  0.5000  0.5000\n",
      " 0.5000  0.5000  0.5000\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "y=Variable containing:\n",
      " 3.8750  3.8750  3.8750\n",
      " 3.8750  3.8750  3.8750\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "Variable containing:\n",
      " 5.7750  5.7750  5.7750\n",
      " 5.7750  5.7750  5.7750\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "5.775\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.ones(2, 3)*0.5, requires_grad=True)\n",
    "y = 7 * x**3 + 3\n",
    "print(\"x={0}\\ny={1}\".format(x,y))\n",
    "y.backward(gradient=torch.ones(2,3)*1.1)\n",
    "print(x.grad)\n",
    "print(7*3*(0.5**2)*1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我还不是很理解\n",
    "```python \n",
    "y.backward(gradient=torch.ones(2,3)*1.1)\n",
    "```\n",
    "中gradient的定义\n",
    "从计算的结果上来看是\n",
    "求出\n",
    "$$\n",
    "\\frac{dy}{dx}|_{x=x.data} \\times gradient\n",
    "$$\n",
    "对于\n",
    "$$\n",
    "y=7 x ^3+3\n",
    "\\\\\n",
    "\\frac{dy}{dx}=21 x^2, 代入x=0.5\n",
    "\\\\\n",
    "21\\times (0.5)^2\n",
    "然后再乘以gradient = 1.1\n",
    "\\\\\n",
    "21\\times (0.5)^2 \\times 1.1 = 5.775\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在http://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html 例题里面用的参数不太好, 其中的Xi和gradient都是取的1, 容易混淆. \n",
    "注意如果z.backward()里面的gradient不省略的话, 维度应当和z本身一致. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T10:50:12.774374Z",
     "start_time": "2017-11-19T10:50:12.752386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 18.0000  18.0000\n",
      " 18.0000  18.0000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 37.9473  37.9473  37.9473\n",
      " 37.9473  37.9473  37.9473\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "37.947331922\n"
     ]
    }
   ],
   "source": [
    "x1 = Variable(torch.ones(2, 3)*np.sqrt(2), requires_grad=True)\n",
    "x2 = Variable(torch.ones(3, 2)*np.sqrt(3), requires_grad=True)\n",
    "y1 = torch.sqrt(x1)\n",
    "z = torch.mm(x1**2,x2**2)\n",
    "print(z)\n",
    "z.backward(gradient=torch.ones(2,2)*np.sqrt(5))\n",
    "print(x1.grad)\n",
    "print(2*np.sqrt(2)*\n",
    "      (np.sqrt(3)**2+np.sqrt(3)**2)\n",
    "        *np.sqrt(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "70px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
